{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8161c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#fetches content of url\n",
    "# Standard headers to fetch a website\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a13dd5",
   "metadata": {},
   "source": [
    "Build the function that will be used to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28da93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_website_contents(url):\n",
    "    \"\"\"\n",
    "    Return the title and contents of the website at the given url;\n",
    "    truncate to 2,000 characters as a sensible limit\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    if soup.body:\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return (title + \"\\n\\n\" + text)[:2_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b4723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_website_links(url):\n",
    "    \"\"\"\n",
    "    Return the links on the webiste at the given url\n",
    "    I realize this is inefficient as we're parsing twice! This is to keep the code in the lab simple.\n",
    "    Feel free to use a class and optimize it!\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "    return [link for link in links if link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66318477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b6b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "# load_dotenv(override=True)\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "#     print(\"API key looks good so far\")\n",
    "# else:\n",
    "#     print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'deepseek-coder:1.3b'  # or 'llama3.2:1b' if you pulled the smaller model\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6870a1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/zai-org/GLM-Image',\n",
       " '/fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA',\n",
       " '/Lightricks/LTX-2',\n",
       " '/openbmb/AgentCPM-Explore',\n",
       " '/kyutai/pocket-tts',\n",
       " '/models',\n",
       " '/spaces/multimodalart/qwen-image-multiple-angles-3d-camera',\n",
       " '/spaces/mrfakename/Z-Image-Turbo',\n",
       " '/spaces/Wan-AI/Wan2.2-Animate',\n",
       " '/spaces/prithivMLmods/Qwen-Image-Edit-2511-LoRAs-Fast',\n",
       " '/spaces/linoyts/Qwen-Image-Edit-Angles',\n",
       " '/spaces',\n",
       " '/datasets/HuggingFaceFW/finetranslations',\n",
       " '/datasets/MiniMaxAI/OctoCodingBench',\n",
       " '/datasets/Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b',\n",
       " '/datasets/miromind-ai/MiroVerse-v0.1',\n",
       " '/datasets/ScienceOne-AI/S1-MMAlign',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/inference/models',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord',\n",
       " 'https://www.zhihu.com/org/huggingface',\n",
       " 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/chinese-language-blog/wechat.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = fetch_website_links(\"https://huggingface.co/\")\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b59a6c",
   "metadata": {},
   "source": [
    "### Use a call to gpt-5-nano to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1216e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4fef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "You should respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "267bd1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(url):\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt += \"\\n\".join(links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061de4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the list of links on the website https://huggingface.co/ -\n",
      "Please decide which of these are relevant web links for a brochure about the company, \n",
      "respond with the full https URL in JSON format.\n",
      "Do not include Terms of Service, Privacy, email links.\n",
      "\n",
      "Links (some might be relative links):\n",
      "\n",
      "/\n",
      "/models\n",
      "/datasets\n",
      "/spaces\n",
      "/docs\n",
      "/enterprise\n",
      "/pricing\n",
      "/login\n",
      "/join\n",
      "/spaces\n",
      "/models\n",
      "/zai-org/GLM-Image\n",
      "/fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA\n",
      "/Lightricks/LTX-2\n",
      "/openbmb/AgentCPM-Explore\n",
      "/kyutai/pocket-tts\n",
      "/models\n",
      "/spaces/multimodalart/qwen-image-multiple-angles-3d-camera\n",
      "/spaces/mrfakename/Z-Image-Turbo\n",
      "/spaces/Wan-AI/Wan2.2-Animate\n",
      "/spaces/prithivMLmods/Qwen-Image-Edit-2511-LoRAs-Fast\n",
      "/spaces/linoyts/Qwen-Image-Edit-Angles\n",
      "/spaces\n",
      "/datasets/HuggingFaceFW/finetranslations\n",
      "/datasets/MiniMaxAI/OctoCodingBench\n",
      "/datasets/Alibaba-Apsara/Superior-Reasoning-SFT-gpt-oss-120b\n",
      "/datasets/miromind-ai/MiroVerse-v0.1\n",
      "/datasets/ScienceOne-AI/S1-MMAlign\n",
      "/datasets\n",
      "/join\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/enterprise\n",
      "/inference/models\n",
      "/pricing#endpoints\n",
      "/pricing#spaces\n",
      "/pricing\n",
      "/allenai\n",
      "/facebook\n",
      "/amazon\n",
      "/google\n",
      "/Intel\n",
      "/microsoft\n",
      "/grammarly\n",
      "/Writer\n",
      "/docs/transformers\n",
      "/docs/diffusers\n",
      "/docs/safetensors\n",
      "/docs/huggingface_hub\n",
      "/docs/tokenizers\n",
      "/docs/trl\n",
      "/docs/transformers.js\n",
      "/docs/smolagents\n",
      "/docs/peft\n",
      "/docs/datasets\n",
      "/docs/text-generation-inference\n",
      "/docs/accelerate\n",
      "/models\n",
      "/datasets\n",
      "/spaces\n",
      "/changelog\n",
      "https://endpoints.huggingface.co\n",
      "/chat\n",
      "/huggingface\n",
      "/brand\n",
      "/terms-of-service\n",
      "/privacy\n",
      "https://apply.workable.com/huggingface/\n",
      "mailto:press@huggingface.co\n",
      "/learn\n",
      "/docs\n",
      "/blog\n",
      "https://discuss.huggingface.co\n",
      "https://status.huggingface.co/\n",
      "https://github.com/huggingface\n",
      "https://twitter.com/huggingface\n",
      "https://www.linkedin.com/company/huggingface/\n",
      "/join/discord\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(\"https://huggingface.co/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3db8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    return links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ab62253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'homepage', 'url': 'http://web.huggingface.co'},\n",
       "  {'Relative Link Name1 },   [': 'About Page',\n",
       "   \"https:/full-path-to--about/endpoint2],     ...]]}])...]} }..]}]}}  ],         The code for the above request is not provided here and I'm sorry if you find it confusing. But, a list of all available company pages that are linked in this context can be obtained using some sorting algorithm or regular expressions to identify \": \", then follow with its immediate path-to endpoint URLs as follows `https:/full-path/endpoint` . Please replace hyphens '-' and brackets '[]'.  The rest of the tasks is a mix between your request regarding making sure not including terms, privacy policies or any other related information in response. If there are no available company pages under this context then an empty list should be provided as per requirement `[ ]` . In case you want to link all relative links separately and their respective full URLs also include it otherwise we can consider them separate entries (i.e., {\"},\n",
       "  {\" .... }). Here is the python code snippet for this: ...]}])%))/...)... %} as in given c++ request but I am not sure about `https:/full-path` meaning, or how to replace it based on provided links and provide a full url using Python script. You might have some specific rules of replacing with the proper implementation is required here .. you can put only one link per URL format (as in your example) that would be more appropriate as I am not sure about actual requirements from this context ...].}]}}, [[...]] }) ]) %}} })) ....   In case there are no relative links or all provided details were mistaken, could someone provide me with a different set if required. Then we can make use of it to proceed further in the brochure creation process by replacing given '..' according to requirement []. This request and response format should follow best practice for data interchanging within an API based system such as this one ...]]}}...  ],     \": {}},\n",
       "  {'Type': '...', 'url': ['']},\n",
       "  {'type': 'ContactUs',\n",
       "   'path_to endpoint2-1`}}} .... `(in your given example) ]}]}))})))```} ) ...]]}}]))).  In case there are no available company pages under this context then an empty list should be provided as per requirement []. } ],    {...]},   [[{': 'Alliance for AI',\n",
       "   'url': '/spaces/alliancesforai'},\n",
       "  {'type:': 'About Page',\n",
       "   'path_to endpoint2-1`}  ... ]]]})) }) ) %}```}) %}}] }}...... In case there are no available company pages under this context then an empty list should be provided as per requirement `[[]]} [)}...)) ..]))}': 'CompanyWebsite',\n",
       "   'url': '/company/websites'}],\n",
       " ', ...]]])  ]} }) %}}`,  `[[{    {': ','}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://huggingface.co/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecda1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    print(f\"Selecting relevant links for {url} by calling {MODEL}\")\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"} #new add to return result in json format\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    links = json.loads(result)\n",
    "    print(f\"Found {len(links['links'])} relevant links\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "650724e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co/ by calling deepseek-coder:1.3b\n",
      "Found 3 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'About Page', 'url': 'https://www.huggingface.co/'},\n",
       "  {'type': '/models', 'url': 'https://github.com'},\n",
       "  {'type': '/datasets', 'url': 'https://aws.amazon.com/dataset-storage'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(\"https://huggingface.co/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299bbeae",
   "metadata": {},
   "source": [
    "Second Step: tO make the bourchure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "497a1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    contents = fetch_website_contents(url)\n",
    "    relevant_links = select_relevant_links(url)\n",
    "\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "\n",
    "    for link in relevant_links.get(\"links\", []):\n",
    "        link_type = link.get(\"type\") or link.get(\"name\") or \"Unknown\"\n",
    "        link_url = link.get(\"url\")\n",
    "\n",
    "        # Skip invalid entries\n",
    "        if not link_url:\n",
    "            continue\n",
    "\n",
    "        result += f\"\\n\\n### Link: {link_type}\\n\"\n",
    "        result += fetch_website_contents(link_url)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b2bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting relevant links for https://huggingface.co/ by calling deepseek-coder:1.3b\n",
      "Found 3 relevant links\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '/chat/': No scheme supplied. Perhaps you meant https:///chat/?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMissingSchema\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfetch_page_and_all_relevant_links\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://huggingface.co/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mfetch_page_and_all_relevant_links\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     15\u001b[39m     result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m### Link: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlink_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     result += \u001b[43mfetch_website_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mfetch_website_contents\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_website_contents\u001b[39m(url):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Return the title and contents of the website at the given url;\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    truncate to 2,000 characters as a sensible limit\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     soup = BeautifulSoup(response.content, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     title = soup.title.string \u001b[38;5;28;01mif\u001b[39;00m soup.title \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo title found\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hala mohamed\\projects\\llm_engineering\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hala mohamed\\projects\\llm_engineering\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hala mohamed\\projects\\llm_engineering\\.venv\\Lib\\site-packages\\requests\\sessions.py:575\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[32m    563\u001b[39m req = Request(\n\u001b[32m    564\u001b[39m     method=method.upper(),\n\u001b[32m    565\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    573\u001b[39m     hooks=hooks,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m prep = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m proxies = proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    579\u001b[39m settings = \u001b[38;5;28mself\u001b[39m.merge_environment_settings(\n\u001b[32m    580\u001b[39m     prep.url, proxies, stream, verify, cert\n\u001b[32m    581\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hala mohamed\\projects\\llm_engineering\\.venv\\Lib\\site-packages\\requests\\sessions.py:484\u001b[39m, in \u001b[36mSession.prepare_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    481\u001b[39m     auth = get_netrc_auth(request.url)\n\u001b[32m    483\u001b[39m p = PreparedRequest()\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hala mohamed\\projects\\llm_engineering\\.venv\\Lib\\site-packages\\requests\\models.py:367\u001b[39m, in \u001b[36mPreparedRequest.prepare\u001b[39m\u001b[34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_method(method)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_headers(headers)\n\u001b[32m    369\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_cookies(cookies)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hala mohamed\\projects\\llm_engineering\\.venv\\Lib\\site-packages\\requests\\models.py:438\u001b[39m, in \u001b[36mPreparedRequest.prepare_url\u001b[39m\u001b[34m(self, url, params)\u001b[39m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(*e.args)\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scheme:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[32m    439\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No scheme supplied. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    441\u001b[39m     )\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: No host supplied\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mMissingSchema\u001b[39m: Invalid URL '/chat/': No scheme supplied. Perhaps you meant https:///chat/?"
     ]
    }
   ],
   "source": [
    "print(fetch_page_and_all_relevant_links(\"https://huggingface.co/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
